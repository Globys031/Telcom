from sklearn.datasets import make_blobs
from sklearn.ensemble import IsolationForest
from sklearn.decomposition import PCA

from numpy import quantile, random, where
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import warnings

from plotly.offline import download_plotlyjs, init_notebook_mode, plot, plot
import plotly.graph_objs as go

###########
# The "getAnomalyIndexes" and "drawAnomaliesAllColumns" display anomalies based on all columns
# The rest of the code goes by each column and further defines why each column's data
# can be considered an anomaly.

# % change shows how much the data in the row above differs from the data in the row below

# How data is portrayed in the table:
# * gray - not an anomaly
# * yellow - a small anomaly (can be safely ignored)
# * red - anomaly
# As for the graph, both the yellow (insignifcant) and the red anomalies are portrayed as red
###########

class AnomalyDetector:
  def __init__(self, learning_data):
    self.learning_data = learning_data

  def printInput(self):
    print(self.learning_data)

  # Currently there's no contamination as there's no attack data examples. But you can't have
  # contamination = 0. So for now 0.01 will suffice.
  # TO DO: gather (or generate yourself) attack data. We'll later use the algorithm to check if
  # that data appears as anomalies
  def getAnomalyIndexes(self):
    # We're going to use all columns for anomaly detection
    # The only column that might not be of importance is "time", but for now we'll leave it as is.
    # contamination - percentage of outlier points in the data
    model=IsolationForest(n_estimators=100, max_samples='auto', contamination=0.01,
                          max_features=1.0, bootstrap=False, n_jobs=-1, random_state=42, verbose=0)
    # Fits the models and makes predictions on whether there's outliers
    model.fit(self.learning_data.values)
    self.learning_data['anomaly'] = model.predict(self.learning_data.values)
    outliers = self.learning_data.loc[self.learning_data['anomaly'] == -1]

    # Gets the indexes of data that are anomalies
    return list(outliers.index)


  def drawAnomaliesAllColumns(self, outlier_indexes):
    # PCA is primarily used for dimensionality reduction (basically allows to display multiple columns in 2D)
    pca = PCA(2)
    pca.fit(self.learning_data.values)

    # It seems to be calculated differently every time
    transformed_data = pd.DataFrame(pca.transform(self.learning_data.values))

    plt.title("IsolationForest")

    b1 = plt.scatter(transformed_data[0], transformed_data[1], c='green', s=20,label="normal points")
    b1 = plt.scatter(transformed_data.iloc[outlier_indexes, 0], transformed_data.iloc[outlier_indexes, 1], c='red',s=20,label="predicted outliers")
    
    plt.legend(loc="upper right")
    plt.show()

  #######################################################################
  #### Below is the actual meat of the code
  #######################################################################

  # Identifies anomalies in all columns(metrics)
  def identifyAnomalies(self):
    model=IsolationForest(n_estimators=100, max_samples='auto', contamination=0.01,
                          max_features=1.0, bootstrap=False, n_jobs=-1, random_state=42, verbose=0)
    warnings.filterwarnings('ignore')

    # "load_date" is only used for graphical purposes so it needs to be skipped
    for i in range(1,len(self.learning_data.columns)-1):
      # uses isolation forest for each column separately. This weird way of declaring is used to preserve
      # the column name and get only the data for that column
      model.fit(self.learning_data.iloc[:,i:i+1])
      pred = model.predict(self.learning_data.iloc[:,i:i+1])

      test_df = pd.DataFrame()
      test_df['load_date'] = self.learning_data['load_date']
      #Find decision function to find the score and classify anomalies
      test_df['score'] = model.decision_function(self.learning_data.iloc[:,i:i+1])
      # 'actuals' is the actual column data generated by dataGenerator
      test_df['actuals'] = self.learning_data.iloc[:,i:i+1]
      # 'anomaly' aren't anomalies. They're predictions (1 or -1).
      test_df['anomaly'] = pred

      test_df = self.classifyMetricAnomalies(test_df, self.learning_data.columns[i])
      self.plotAnomalies(test_df,self.learning_data.columns[i])

      # figures.append(self.plotAnomalies(test_df,self.learning_data.columns[i]))
      # iplot(figures)
      # plt.show()
  

  # Takes one column (metric_name) as an argument
  # and classifies what data in that column is not an anomaly/lowanomaly/high anomaly
  def classifyMetricAnomalies(self, df, metric_name):
    df = df.sort_values(by='load_date', ascending=False)

    # Shift actuals (data generated by dataGenerator) 
    # by one timestamp to find the percentage change between current and previous data point
    df['shift'] = df['actuals'].shift(-1)

    df['percentage_change'] = ((df['actuals'] - df['shift']) / df['actuals']) * 100

    # Anomalies are further categorised as:
    # 0-no anomaly, 1- low anomaly , 2 - high anomaly
    df['anomaly'].loc[df['anomaly'] == 1] = 0
    df['anomaly'].loc[df['anomaly'] == -1] = 2

    max_anomaly_score = df['score'].loc[df['anomaly'] == 2].max()
    medium_percentile = df['score'].quantile(0.24)
    df['anomaly'].loc[(df['score'] > max_anomaly_score) & (df['score'] <= medium_percentile)] = 1

    return df

  def plotAnomalies(self, df, metric_name):
    # init_notebook_mode(connected=True)

    dates = df['load_date']

    #identify anomaly points and create an array of anomaly's values for plot
    bool_array = (abs(df['anomaly']) > 0)
    actuals = df["actuals"][-len(bool_array):]
    # All of the non-anomaly values are going to be NaN
    anomaly_points = bool_array * actuals
    anomaly_points[anomaly_points == 0] = np.nan

    #A dictionary for conditional format table based on anomaly
    color_map = {0: "gray", 1: "yellow", 2: "red"}
    
    #Table which includes Date,Actuals(dataGenerator values),Change occured from previous point
    # https://plotly.com/python/table/
    table = go.Table(
        domain=dict(x=[0, 1],
                    y=[0, 0.55]),
        columnwidth=[5, 2, 3],
        header=dict(height=20,
                    values=[['<b>Date</b>'], ['<b>Actual Values </b>'], ['<b>% Change </b>'],
                            ],
                    font=dict(color=['rgb(45,45,45)'] * 5, size=14),
                    fill=dict(color='#d562be')), #bet issiaiskinau kad tikrai sita vieta jam nepatinka
        cells=dict(values=[df.round(3)[k].tolist() for k in ['load_date', 'actuals', 'percentage_change']],
                   line=dict(color='#506784'),
                   align=['center'] * 5,
                   font=dict(color=['rgb(40,40,40)'] * 5, size=12),
                   suffix=[None] + [''] + [''] + ['%'] + [''],
                   height=27,
                   fill=dict(color=[df['anomaly'].map(color_map)],#map based on anomaly level from dictionary
                   )
                   ))
    #Plot the actuals (datagenerator data) scatter points
    Actuals = go.Scatter(name='Actuals',
                         x=dates,
                         y=df['actuals'],
                         xaxis='x1', yaxis='y1',
                         mode='lines',
                         marker=dict(size=12,
                                     line=dict(width=1),
                                     color="blue"))
    #Highlight the anomaly points
    anomalies_map = go.Scatter(name="Anomaly",
                               showlegend=True,
                               x=dates,
                               y=anomaly_points,
                               mode='markers',
                               xaxis='x1',
                               yaxis='y1',
                               marker=dict(color="red",
                                           size=11,
                                           line=dict(
                                               color="red",
                                               width=2)))
    axis = dict(
            showline=True,
            zeroline=False,
            showgrid=True,
            mirror=True,
            ticklen=4,
            gridcolor='#ffffff',
            tickfont=dict(size=10))
    layout = dict(
            width=1000,
            height=865,
            autosize=False,
            title=metric_name,
            margin=dict(t=75),
            showlegend=True,
            xaxis1=dict(axis, **dict(domain=[0, 1], anchor='y1', showticklabels=True)),
            yaxis1=dict(axis, **dict(domain=[2 * 0.21 + 0.20, 1], anchor='x1', hoverformat='.2f')))
    fig = go.Figure(data=[table, anomalies_map, Actuals], layout=layout)

    plot(fig)
  